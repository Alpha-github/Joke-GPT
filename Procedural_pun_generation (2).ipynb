{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hm_hTEoEgYsC"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel , GPT2Tokenizer\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "class trieNode():\n",
        "\n",
        "  def __init__(self, letter = None):\n",
        "\n",
        "    # Keep track of children as nodes and letters\n",
        "    self.children = []\n",
        "    self.children_nodes = [] \n",
        "    self.is_leaf = False\n",
        "    self.letter = letter\n",
        "\n",
        "    # Utility: store the \"words\" up to this point, \n",
        "    # as well as all the child strings that follow this.\n",
        "    # This exhanges some memory for easier lookup later\n",
        "    # Additionally, we store how many times a node has been visited \n",
        "    self.string = None\n",
        "    self.child_strings = []\n",
        "    self.visited = 0\n",
        "\n",
        "class Trie():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.root = trieNode()\n",
        "    self.n_nodes = 0\n",
        "\n",
        "  def insert(self, key):\n",
        "    \n",
        "    # Start at the root\n",
        "    pointer = self.root\n",
        "    \n",
        "    idx = 0\n",
        "\n",
        "    for i in key:\n",
        "      if i in pointer.children: # If the child exists\n",
        "        order = pointer.children.index(i) # simply move forward\n",
        "        pointer = pointer.children_nodes[order]\n",
        "      else: # Otherwise create and append a new node\n",
        "        pointer.children.append(i)\n",
        "        pointer.children_nodes.append(trieNode(i))\n",
        "        self.n_nodes += 1\n",
        "        pointer = pointer.children_nodes[-1]\n",
        "        pointer.string = key[0:(idx + 1)]\n",
        "      \n",
        "      # Update the other values\n",
        "      pointer.visited += 1\n",
        "\n",
        "      # ...and if the node is a leaf, or if we should simply add new children\n",
        "      idx += 1\n",
        "      if idx == len(key):\n",
        "        pointer.is_leaf = True\n",
        "      else:\n",
        "        pointer.child_strings.append(key[(idx):len(key)]) \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "825SWKNGv4A6"
      },
      "source": [
        "## Helper functions\n",
        "\n",
        "These functions help us create the needed data structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J_S7_u8bv1WN"
      },
      "outputs": [],
      "source": [
        "def create_dict(trie):\n",
        "\n",
        "  result = {}\n",
        "\n",
        "  def crawl(trie):\n",
        "\n",
        "    if len(trie.children_nodes) == 0:\n",
        "      return\n",
        "\n",
        "    if trie.is_leaf and len(trie.children) > 0:\n",
        "      for child_string in trie.child_strings:\n",
        "        if child_string not in result.keys():\n",
        "          result[child_string] = []\n",
        "        result[child_string].append(trie.string)\n",
        "\n",
        "    for child in trie.children_nodes:\n",
        "\n",
        "      crawl(child)\n",
        "  \n",
        "  crawl(trie)\n",
        "\n",
        "  return result\n",
        "\n",
        "def create_flipped_dict(trie):\n",
        "\n",
        "  result = {}\n",
        "\n",
        "  def crawl(trie):\n",
        "\n",
        "    if len(trie.children_nodes) == 0:\n",
        "      return\n",
        "\n",
        "    if trie.is_leaf and len(trie.children) > 0:\n",
        "      for child_string in trie.child_strings:\n",
        "        flipped_string = child_string[::-1]\n",
        "        if flipped_string not in result.keys():\n",
        "          result[flipped_string] = []\n",
        "        result[flipped_string].append(trie.string[::-1])\n",
        "\n",
        "    for child in trie.children_nodes:\n",
        "\n",
        "      crawl(child)\n",
        "  \n",
        "  crawl(trie)\n",
        "\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0g1JlwOwIgi"
      },
      "source": [
        "## Joke generator class\n",
        "\n",
        "This class handles most of the heavy lifting apart from the GPT-3 connectivity. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gVn5BwP_wBYJ"
      },
      "outputs": [],
      "source": [
        "class jokeGenerator():\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.trie = Trie()\n",
        "    self.flipped_trie = Trie()\n",
        "    self.words = None\n",
        "\n",
        "    self.result = None\n",
        "    self.flipped_result = None\n",
        "    self.common_keys = None\n",
        "    \n",
        "    self.wordplays = None\n",
        "\n",
        "    self.tokenizer = None\n",
        "    self.model = None\n",
        "\n",
        "  def loadWords(self, source):\n",
        "\n",
        "    words = pd.read_csv(source, na_filter = False)\n",
        "    words = words.values.tolist()\n",
        "    words = [x[0] for x in words]    \n",
        "\n",
        "    print(f'Loading {len(words)} words')\n",
        "\n",
        "    i = 0\n",
        "    n_words = len(words)\n",
        "    for word in words:\n",
        "      i += 1\n",
        "      if i % int(n_words/10) == 0:\n",
        "        print(f'{int((i+1)/n_words*100)}% ({i}/{n_words})')\n",
        "      self.trie.insert(word)\n",
        "      self.flipped_trie.insert(word[::-1])\n",
        "\n",
        "    print(f'Done')\n",
        "\n",
        "    self.words = words\n",
        "\n",
        "  # normal: all words\n",
        "  # not_short: the connector is longer than 2 characters\n",
        "  # not_a_word: all words, where the connecting word is not a word in itself\n",
        "  # not_a_short_word: all words, where the connecting word is not a word in itself and it is more than 2 chracters\n",
        "  # not_a_short_word_or_ing: all words, where the connecting word is not a word in itself and it is more than 2 chracters and is not \"ing\"\n",
        "  def generateWords(self, type = 'normal'):\n",
        "\n",
        "    if self.flipped_trie == None or self.trie == None:\n",
        "      print('You must load the words first: loadWords(source)')\n",
        "\n",
        "    self.flipped_result = create_flipped_dict(self.flipped_trie.root)\n",
        "    self.result = create_dict(self.trie.root)\n",
        "\n",
        "    common_keys = list(set(self.result.keys()).intersection(self.flipped_result.keys()))\n",
        "\n",
        "    if type == 'normal':\n",
        "      self.common_keys = common_keys\n",
        "    elif type == 'not_short':\n",
        "      self.common_keys = [x for x in common_keys if (len(x) > 2)]\n",
        "    elif type == 'not_a_word':\n",
        "      self.common_keys = [x for x in common_keys if (x not in self.words and x != '-')]\n",
        "    elif type == 'not_a_short_word':\n",
        "      self.common_keys = [x for x in common_keys if (x not in self.words and x != '-' and len(x) > 2)]\n",
        "    elif type == 'not_a_short_word_or_ing':\n",
        "      self.common_keys = [x for x in common_keys if (x not in self.words and x != '-' and x != 'ing' and len(x) > 2)]\n",
        "\n",
        "    self.wordplays = {}\n",
        "    for c_key in self.common_keys:\n",
        "      for r in self.result[c_key]:\n",
        "        for f_r in self.flipped_result[c_key]:\n",
        "          self.wordplays[f'{r}_{c_key}_{f_r}'] = [f'{r}', f'{c_key}',f'{f_r}']\n",
        "                    \n",
        "  def loadModels(self, language = 'english'):\n",
        "\n",
        "    if language == 'finnish':\n",
        "      self.tokenizer = GPT2Tokenizer.from_pretrained('Finnish-NLP/gpt2-finnish') \n",
        "      self.model = GPT2LMHeadModel.from_pretrained('Finnish-NLP/gpt2-finnish')\n",
        "    elif language == 'english':\n",
        "      self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large') \n",
        "      self.model = GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
        "    # Adding new languages is laughably easy. Search for a passable model on Huggingface, chuck it here and let the script do it's magic.\n",
        "\n",
        "  def generateJoke(self, first_string = '', second_string = '', n = 1, length = 30):\n",
        "    joke = self.wordplays[random.choice(list(self.wordplays.keys()))]\n",
        "    joke_words = joke[0] + joke[1] + ' and ' + joke[1] + joke[2]   \n",
        "    joke_string = first_string + ' ' + joke_words + ' ' + second_string\n",
        "\n",
        "    input_ids = self.tokenizer.encode(joke_string, return_tensors = 'pt')\n",
        "\n",
        "    output = self.model.generate(input_ids, \n",
        "                        max_length = length,\n",
        "                        num_beams = n, \n",
        "                        num_return_sequences = n,\n",
        "                        no_repeat_ngram_size  = 3)\n",
        "    \n",
        "    result = []\n",
        "    for op in output:\n",
        "      result.append(self.tokenizer.decode(op))\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7CK0Yjri2qs"
      },
      "source": [
        "## Examples\n",
        "\n",
        "After running the abovementioned scripts, you can run the following. You will need a dictionary of words. I used [this](http://www.mieliestronk.com/corncob_lowercase.txt) wonderful corpus, but feel free to plug in your own in any language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tSRZNtXQi4AL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading 58109 words\n",
            "10% (5810/58109)\n",
            "19% (11620/58109)\n",
            "29% (17430/58109)\n",
            "39% (23240/58109)\n",
            "49% (29050/58109)\n",
            "59% (34860/58109)\n",
            "69% (40670/58109)\n",
            "79% (46480/58109)\n",
            "89% (52290/58109)\n",
            "99% (58100/58109)\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# Initialize the class\n",
        "eng_gen = jokeGenerator()\n",
        "\n",
        "# Load the words from online or from disk. This can be in any language\n",
        "eng_gen.loadWords('http://www.mieliestronk.com/corncob_lowercase.txt')\n",
        "# The generator has multiple filters to filter naive solutions - let's use setting \"connector is not a word, is longer than 2 characters and is not _ing_\"\n",
        "eng_gen.generateWords('not_a_short_word_or_ing')\n",
        "# You can add mode languages above by finding a suitable transformer model in your language and substituting above\n",
        "eng_gen.loadModels('english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ZTwFC2yHSo"
      },
      "source": [
        "You can explore the dyads of words by sampling from the wordplays-dictionary in the generator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r06pZTPuyOWZ"
      },
      "outputs": [],
      "source": [
        "# eng_gen.wordplays[random.choice(list(eng_gen.wordplays.keys()))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHJaYl5JyCsb"
      },
      "source": [
        "You can generate jokes using the provided GPT engine by calling the generateJoke() method. These are generally rather poor in quality, but nonetheless you can enjoy your 100% artificially created humor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n2ZVxo-KjIyN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[\"Tell me a joke about gloomful and fulfilling \\xa0the world is a better place when you're not there.\\nI'm not sure what the point of this is, but I'm sure it's a good one.\\nThe point is that I'm not going to be there. I'm going to go to the movies, I'm gonna go to a concert, I'll go to dinner\"]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_gen.generateJoke('Tell me a joke about', n = 1, length = 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoSxH1M_yfUK"
      },
      "source": [
        "## OpenAI GPT-3\n",
        "\n",
        "The following utilizes the OpenAI GPT-3 model. It is not free, but yield _much_ better results than the free transformers. Some might even call it humor. See [https://beta.openai.com/](https://beta.openai.com/) to sign up for your API key. You can call the API using the following prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "11j8sHwLXqJV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "words = eng_gen.wordplays[random.choice(list(eng_gen.wordplays.keys()))]\n",
        "input_word = ''.join(words[0:2]) + ' ' + words[2] + ' and ' + words[0] + ' ' + ''.join(words[1:3])\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "result = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt=f\"Write a joke containing the words '{input_word}'\",\n",
        "  max_tokens=60,\n",
        "  temperature = 0.3,\n",
        "  n = 1,\n",
        "  echo = True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W6w7F0izKpR"
      },
      "source": [
        "and fetch the resulting joke as such:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JI__K-b5YAXm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Write a joke containing the words 'papas ted and pa pasted'\\n\\nWhy did Papas Ted and Pa Pasted cross the road?\\n\\nTo get to the other side!\""
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.to_dict()['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkklhXdNzUo_"
      },
      "source": [
        "Let's finally create a helper function to come up with any number of jokes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tDgdxISVcl2M"
      },
      "outputs": [],
      "source": [
        "def create_jokes(wordplays, n, api_key):\n",
        "\n",
        "  results = pd.DataFrame({'input' : [], 'prompt' : [], 'answer' : []})\n",
        "  openai.api_key = api_key\n",
        "\n",
        "  for i in range(n):\n",
        "\n",
        "    words = wordplays[random.choice(list(wordplays.keys()))]\n",
        "    input_word = ''.join(words[0:2]) + ' ' + words[2] + ' and ' + words[0] + ' ' + ''.join(words[1:3])\n",
        "    prompt = f\"Write a joke containing the words '{input_word}'\"\n",
        "\n",
        "    result = openai.Completion.create(\n",
        "      engine=\"text-davinci-002\",\n",
        "      prompt=prompt,\n",
        "      max_tokens=60,\n",
        "      temperature = 0.3,\n",
        "      n = 1\n",
        "    )\n",
        "    answer = [input_word, prompt, result.to_dict()['choices'][0]['text']]\n",
        "\n",
        "    results.loc[len(results)] = answer\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaot6FPk0jvO"
      },
      "source": [
        "Call it like so"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1VNIGho5zpNa"
      },
      "outputs": [],
      "source": [
        "jokes = create_jokes(eng_gen.wordplays, 10, \"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\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jLdDoySQSC1"
      },
      "source": [
        "And check the resulting jokes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o9idj45e0b9-"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>prompt</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>laughter mites and laugh termites</td>\n",
              "      <td>Write a joke containing the words 'laughter mi...</td>\n",
              "      <td>\\n\\nWhat do you call laughter mites that infes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>carbon us and car bonus</td>\n",
              "      <td>Write a joke containing the words 'carbon us a...</td>\n",
              "      <td>\\n\\nWhat do you call a carbon that's also a ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ponderous ted and ponder ousted</td>\n",
              "      <td>Write a joke containing the words 'ponderous t...</td>\n",
              "      <td>\\n\\nWhy did the chicken cross the road? To get...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tugela borate and tug elaborate</td>\n",
              "      <td>Write a joke containing the words 'tugela bora...</td>\n",
              "      <td>\\n\\nWhy did the tugela borate the tug elaborat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ohmic robes and oh microbes</td>\n",
              "      <td>Write a joke containing the words 'ohmic robes...</td>\n",
              "      <td>\\n\\nWhat do you call a Jedi who only wears ohm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>refund id and ref undid</td>\n",
              "      <td>Write a joke containing the words 'refund id a...</td>\n",
              "      <td>\\n\\nI tried to get a refund for my gym members...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>genres canning and gen rescanning</td>\n",
              "      <td>Write a joke containing the words 'genres cann...</td>\n",
              "      <td>\\n\\nWhy did the chicken cross the road? To get...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>scoopful filled and scoop fulfilled</td>\n",
              "      <td>Write a joke containing the words 'scoopful fi...</td>\n",
              "      <td>\\n\\nI was going to make some ice cream, but I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>snugger ontology and snug gerontology</td>\n",
              "      <td>Write a joke containing the words 'snugger ont...</td>\n",
              "      <td>\\n\\nWhat's the difference between snugger onto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bedsitter mite and bedsit termite</td>\n",
              "      <td>Write a joke containing the words 'bedsitter m...</td>\n",
              "      <td>\\n\\nWhat's the difference between a bedsitter ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   input  \\\n",
              "0      laughter mites and laugh termites   \n",
              "1                carbon us and car bonus   \n",
              "2        ponderous ted and ponder ousted   \n",
              "3        tugela borate and tug elaborate   \n",
              "4            ohmic robes and oh microbes   \n",
              "5                refund id and ref undid   \n",
              "6      genres canning and gen rescanning   \n",
              "7    scoopful filled and scoop fulfilled   \n",
              "8  snugger ontology and snug gerontology   \n",
              "9      bedsitter mite and bedsit termite   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  Write a joke containing the words 'laughter mi...   \n",
              "1  Write a joke containing the words 'carbon us a...   \n",
              "2  Write a joke containing the words 'ponderous t...   \n",
              "3  Write a joke containing the words 'tugela bora...   \n",
              "4  Write a joke containing the words 'ohmic robes...   \n",
              "5  Write a joke containing the words 'refund id a...   \n",
              "6  Write a joke containing the words 'genres cann...   \n",
              "7  Write a joke containing the words 'scoopful fi...   \n",
              "8  Write a joke containing the words 'snugger ont...   \n",
              "9  Write a joke containing the words 'bedsitter m...   \n",
              "\n",
              "                                              answer  \n",
              "0  \\n\\nWhat do you call laughter mites that infes...  \n",
              "1  \\n\\nWhat do you call a carbon that's also a ca...  \n",
              "2  \\n\\nWhy did the chicken cross the road? To get...  \n",
              "3  \\n\\nWhy did the tugela borate the tug elaborat...  \n",
              "4  \\n\\nWhat do you call a Jedi who only wears ohm...  \n",
              "5  \\n\\nI tried to get a refund for my gym members...  \n",
              "6  \\n\\nWhy did the chicken cross the road? To get...  \n",
              "7  \\n\\nI was going to make some ice cream, but I ...  \n",
              "8  \\n\\nWhat's the difference between snugger onto...  \n",
              "9  \\n\\nWhat's the difference between a bedsitter ...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jokes"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "aac16c045827a40694571c32a5eab65b3bafe70755c551bce7e5d51e33df358c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
