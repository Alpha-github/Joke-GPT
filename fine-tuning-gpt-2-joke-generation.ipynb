{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, random_split\nfrom transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-05T06:11:44.851273Z","iopub.execute_input":"2023-02-05T06:11:44.851638Z","iopub.status.idle":"2023-02-05T06:11:55.982139Z","shell.execute_reply.started":"2023-02-05T06:11:44.851599Z","shell.execute_reply":"2023-02-05T06:11:55.981300Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:11:55.983427Z","iopub.execute_input":"2023-02-05T06:11:55.983747Z","iopub.status.idle":"2023-02-05T06:11:57.043308Z","shell.execute_reply.started":"2023-02-05T06:11:55.983714Z","shell.execute_reply":"2023-02-05T06:11:57.042194Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Sun Feb  5 06:11:56 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:11:57.047913Z","iopub.execute_input":"2023-02-05T06:11:57.050103Z","iopub.status.idle":"2023-02-05T06:11:57.065911Z","shell.execute_reply.started":"2023-02-05T06:11:57.050062Z","shell.execute_reply":"2023-02-05T06:11:57.065105Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7fc5e094e3d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Loading GPT2-Medium Model from ðŸ¤— Model Hub ","metadata":{}},{"cell_type":"code","source":"\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium', bos_token='<|startoftext|>',\n                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2-medium').cuda()\nmodel.resize_token_embeddings(len(tokenizer))\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:11:57.071197Z","iopub.execute_input":"2023-02-05T06:11:57.073134Z","iopub.status.idle":"2023-02-05T06:13:16.673936Z","shell.execute_reply.started":"2023-02-05T06:11:57.073098Z","shell.execute_reply":"2023-02-05T06:13:16.672894Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a689e55409406e8c6395b6fe8c29c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f48cb0785206475287de961a2bc67844"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64387deabdbe4a57bf82a9afc6b46ca6"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be5f9fd52f8f461cafa5941cc940a614"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15bbfedd7c034569a48e6f984c890044"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Embedding(50259, 1024)"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:13:16.675900Z","iopub.execute_input":"2023-02-05T06:13:16.676324Z","iopub.status.idle":"2023-02-05T06:13:16.688738Z","shell.execute_reply.started":"2023-02-05T06:13:16.676282Z","shell.execute_reply":"2023-02-05T06:13:16.686889Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/short-jokes/shortjokes.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"descriptions = pd.read_csv(\"/kaggle/input/short-jokes/shortjokes.csv\")['Joke']","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:13:16.690700Z","iopub.execute_input":"2023-02-05T06:13:16.691555Z","iopub.status.idle":"2023-02-05T06:13:17.251736Z","shell.execute_reply.started":"2023-02-05T06:13:16.691513Z","shell.execute_reply":"2023-02-05T06:13:17.250773Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"max_length = max([len(tokenizer.encode(description)) for description in descriptions])","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:13:17.253132Z","iopub.execute_input":"2023-02-05T06:13:17.253510Z","iopub.status.idle":"2023-02-05T06:14:14.533899Z","shell.execute_reply.started":"2023-02-05T06:13:17.253471Z","shell.execute_reply":"2023-02-05T06:14:14.533013Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class NetflixDataset(Dataset):\n    def __init__(self, txt_list, tokenizer, max_length):\n        self.input_ids = []\n        self.attn_masks = []\n        self.labels = []\n        for txt in txt_list:\n            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>', truncation=True,\n                                       max_length=max_length, padding=\"max_length\")\n            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attn_masks[idx]","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:14:14.535260Z","iopub.execute_input":"2023-02-05T06:14:14.535789Z","iopub.status.idle":"2023-02-05T06:14:14.543065Z","shell.execute_reply.started":"2023-02-05T06:14:14.535749Z","shell.execute_reply":"2023-02-05T06:14:14.542013Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = NetflixDataset(descriptions, tokenizer, max_length=max_length)[:-1000]\ntrain_size = int(0.9 * len(dataset))\ntrain_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:14:14.544601Z","iopub.execute_input":"2023-02-05T06:14:14.544949Z","iopub.status.idle":"2023-02-05T06:15:22.154766Z","shell.execute_reply.started":"2023-02-05T06:14:14.544914Z","shell.execute_reply":"2023-02-05T06:15:22.153695Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:15:22.156253Z","iopub.execute_input":"2023-02-05T06:15:22.156663Z","iopub.status.idle":"2023-02-05T06:15:22.468486Z","shell.execute_reply.started":"2023-02-05T06:15:22.156621Z","shell.execute_reply":"2023-02-05T06:15:22.467613Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"22"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:15:22.469927Z","iopub.execute_input":"2023-02-05T06:15:22.470551Z","iopub.status.idle":"2023-02-05T06:15:22.480219Z","shell.execute_reply.started":"2023-02-05T06:15:22.470482Z","shell.execute_reply":"2023-02-05T06:15:22.479587Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(output_dir='./results', num_train_epochs=1, logging_steps=100, save_steps=5000,\n                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n                                  warmup_steps=10, weight_decay=0.05, logging_dir='./logs', report_to = 'none')\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:15:22.481754Z","iopub.execute_input":"2023-02-05T06:15:22.482089Z","iopub.status.idle":"2023-02-05T06:15:22.494373Z","shell.execute_reply.started":"2023-02-05T06:15:22.482050Z","shell.execute_reply":"2023-02-05T06:15:22.493624Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"Trainer(model=model,  args=training_args, train_dataset=train_dataset, \n        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n                                                              'attention_mask': torch.stack([f[1] for f in data]),\n                                                              'labels': torch.stack([f[0] for f in data])}).train()","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:15:22.497168Z","iopub.execute_input":"2023-02-05T06:15:22.497532Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='14629' max='208491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 14629/208491 44:54 < 9:55:11, 5.43 it/s, Epoch 0.07/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>2.990400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.856100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.823300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.836600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.842100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.810000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.726400</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.801800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.804400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.814900</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.827600</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.766000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.786300</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.824400</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.778100</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.818100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.824900</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.799600</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.821200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.741500</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.750600</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.815600</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.785300</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.790200</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.809900</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.787500</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.851200</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.819200</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.743300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.778100</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.759500</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.781500</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.782700</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.824000</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.753900</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.764000</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.789400</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.796000</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.740200</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.824100</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.785000</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.799800</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.830600</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.832500</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.718000</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.775200</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.801100</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.823100</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>0.763800</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.734200</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>0.803800</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>0.809700</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>0.880400</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>0.806600</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.801800</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>0.714100</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>0.727200</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>0.803700</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>0.729800</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.748500</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>0.793100</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>0.775300</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>0.786200</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>0.741000</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.791500</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>0.727200</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>0.746000</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>0.786900</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>0.731700</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.805300</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>0.775900</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>0.821600</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>0.740800</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>0.742000</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.817100</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>0.759300</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>0.782600</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>0.753000</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>0.737300</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.711600</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>0.736800</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>0.826500</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>0.782000</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>0.750800</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.826000</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>0.750200</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>0.793000</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>0.764100</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>0.728700</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.848400</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>0.839900</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>0.756800</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>0.726500</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>0.747900</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.783600</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>0.768000</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>0.771500</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>0.753000</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>0.840300</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.746400</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>0.774300</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>0.784500</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>0.746200</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>0.769700</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.740300</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>0.733600</td>\n    </tr>\n    <tr>\n      <td>10700</td>\n      <td>0.745100</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>0.698700</td>\n    </tr>\n    <tr>\n      <td>10900</td>\n      <td>0.795500</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.802500</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>0.737700</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>0.767200</td>\n    </tr>\n    <tr>\n      <td>11300</td>\n      <td>0.753800</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>0.751600</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.797200</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>0.800200</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>0.761500</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>0.810000</td>\n    </tr>\n    <tr>\n      <td>11900</td>\n      <td>0.707700</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.793500</td>\n    </tr>\n    <tr>\n      <td>12100</td>\n      <td>0.814900</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>0.742500</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>0.795900</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>0.780600</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.759300</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>0.767200</td>\n    </tr>\n    <tr>\n      <td>12700</td>\n      <td>0.776600</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>0.707600</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>0.778100</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.811100</td>\n    </tr>\n    <tr>\n      <td>13100</td>\n      <td>0.775100</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>0.785300</td>\n    </tr>\n    <tr>\n      <td>13300</td>\n      <td>0.769800</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>0.804300</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.763100</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>0.788200</td>\n    </tr>\n    <tr>\n      <td>13700</td>\n      <td>0.840400</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>0.763100</td>\n    </tr>\n    <tr>\n      <td>13900</td>\n      <td>0.821000</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.757800</td>\n    </tr>\n    <tr>\n      <td>14100</td>\n      <td>0.799000</td>\n    </tr>\n    <tr>\n      <td>14200</td>\n      <td>0.793500</td>\n    </tr>\n    <tr>\n      <td>14300</td>\n      <td>0.717600</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>0.802200</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.720000</td>\n    </tr>\n    <tr>\n      <td>14600</td>\n      <td>0.799400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"### GPT Generated Description","metadata":{}},{"cell_type":"code","source":"generated = tokenizer(\"<|startoftext|> \", return_tensors=\"pt\").input_ids.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_outputs = model.generate(generated, do_sample=True, top_k=50, \n                                max_length=300, top_p=0.95, temperature=1.9, num_return_sequences=20)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, sample_output in enumerate(sample_outputs):\n    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Original Description (Random)","metadata":{}},{"cell_type":"code","source":"pd.options.display.max_colwidth = 1000\ndescriptions.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}